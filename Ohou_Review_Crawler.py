import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import pandas as pd
import time

async def scrape_reviews():
    url = input('ì œí’ˆ URL ì…ë ¥: ')
    product_name = input('ì œí’ˆëª… ì…ë ¥: ')

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        page = await context.new_page()

        await page.goto(url)
        await asyncio.sleep(2)

        # ì´ ë¦¬ë·° ìˆ˜ ì¶”ì¶œ
        total_text = await page.locator('xpath=/html/body/div[1]/div/div/div/div[5]/div/div[1]/div/section[2]/header/h1/span').text_content()
        total_reviews = int(total_text.replace(',', '').strip())

        total_pages = total_reviews // 5 + (1 if total_reviews % 5 != 0 else 0)
        print(f'ğŸ“¦ ì´ ë¦¬ë·°: {total_reviews} â†’ ì´ í˜ì´ì§€: {total_pages}')

        # ë¦¬ë·° íƒ­ í´ë¦­
        await page.locator('xpath=/html/body/div[1]/div/div/div[2]/div[1]/div/div[2]/div[1]/div[1]/p/a').click()
        await asyncio.sleep(2)

        review_data = []
        page_num = 1

        while True:
            print(f'ğŸ“„ í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì¤‘...')
            html = await page.content()
            soup = BeautifulSoup(html, 'html.parser')

            stars = soup.find_all(class_='production-review-item__writer__info__total-star')
            texts = soup.find_all(class_='production-review-item__description')
            items = soup.find_all(class_='production-review-item__name__explain__text hidden-overflow')
            dates = soup.find_all(class_='production-review-item__writer__info__date')

            for star, text, item, date in zip(stars, texts, items, dates):
                review_data.append({
                    'ë³„ì ': star.get('aria-label'),
                    'ë¦¬ë·°': text.get_text(strip=True),
                    'ì˜µì…˜': item.get_text(strip=True),
                    'ë‚ ì§œ': date.get_text(strip=True)
                })

            if page_num >= total_pages:
                print("âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ â†’ ì¢…ë£Œ")
                break

            try:
                next_btn = page.locator('xpath=/html/body/div[1]/div/div/div/div[5]/div/div[1]/div/section[2]/div/ul/li[11]/button')
                await next_btn.click()
                await asyncio.sleep(0.8)
                page_num += 1
            except:
                print("âŒ ë‹¤ìŒ ë²„íŠ¼ ì—†ìŒ ë˜ëŠ” ì˜¤ë¥˜ ë°œìƒ â†’ ì¢…ë£Œ")
                break

        await browser.close()

        # ì €ì¥
        lt = time.localtime()
        df = pd.DataFrame(review_data)
        filename = f'{lt.tm_year}.{lt.tm_mon}.{lt.tm_mday}_{product_name}_ë¦¬ë·°_ì˜¤ëŠ˜ì˜ì§‘.xlsx'
        df.to_excel(filename, index=False)
        print(f"ğŸ‰ ì´ {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ! â†’ {filename}")

if __name__ == "__main__":
    asyncio.run(scrape_reviews())
