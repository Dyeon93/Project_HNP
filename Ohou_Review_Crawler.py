from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import NoSuchElementException
from bs4 import BeautifulSoup
import pandas as pd
import time

# ë“œë¼ì´ë²„ ì„¤ì •
url = input('ì œí’ˆ URL ì…ë ¥: ')
product_name = input('ì œí’ˆëª… ì…ë ¥: ')
service = Service('./chromedriver-win64/chromedriver-win64/chromedriver.exe')
options = webdriver.ChromeOptions()
options.add_argument('--start-maximized')
driver = webdriver.Chrome(service=service, options=options)
driver.get(url)
time.sleep(2)

# ì´ í˜ì´ì§€ ìˆ˜ ê³„ì‚°
total_text = driver.find_element(
    By.XPATH, '/html/body/div[1]/div/div/div/div[5]/div/div[1]/div/section[2]/header/h1/span').text
total_reviews = int(total_text.replace(',', ''))

if total_reviews % 5 == 0:
    total_pages = total_reviews // 5
else:
    total_pages = total_reviews // 5 + 1

print(f'ğŸ“¦ ì´ ë¦¬ë·°: {total_reviews} â†’ ì´ í˜ì´ì§€: {total_pages}')

review_btn = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[2]/div[1]/div/div[2]/div[1]/div[1]/p/a')
review_btn.click()
time.sleep(2)

review_data = []
last_page_html = ""
page_num = 1

while True:
    print(f'ğŸ“„ í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì¤‘...')

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    page_source_now = driver.page_source

    stars = soup.find_all(class_='production-review-item__writer__info__total-star')
    texts = soup.find_all(class_='production-review-item__description')
    items = soup.find_all(class_='production-review-item__name__explain__text hidden-overflow')
    dates = soup.find_all(class_='production-review-item__writer__info__date')

    for star, text, item, date in zip(stars, texts, items, dates):
        review_data.append({
            'ë³„ì ': star.get('aria-label'),
            'ë¦¬ë·°': text.get_text(strip=True),
            'ì˜µì…˜': item.get_text(strip=True),
            'ë‚ ì§œ': date.get_text(strip=True)
        })

    # ë¬´í•œë£¨í”„ ë°©ì§€
    # if page_source_now == last_page_html:
    #     print("âš ï¸ ê°™ì€ í˜ì´ì§€ ë°˜ë³µ ê°ì§€ â†’ ì¢…ë£Œ")
    #     break
    # last_page_html = page_source_now

    # í˜„ì¬ í˜ì´ì§€ê°€ ë§ˆì§€ë§‰ì´ë¼ë©´ ì¢…ë£Œ
    if page_num >= total_pages:
        print("âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ â†’ ì¢…ë£Œ")
        break

    try:
        next_btn = driver.find_element(By.XPATH,
            '/html/body/div[1]/div/div/div/div[5]/div/div[1]/div/section[2]/div/ul/li[11]/button')

        driver.execute_script("arguments[0].click();", next_btn)
        time.sleep(0.8)
        page_num += 1

    except NoSuchElementException:
        print("âŒ ë‹¤ìŒ ë²„íŠ¼ ì—†ìŒ â†’ ì¢…ë£Œ")
        break

driver.quit()

# ì €ì¥
lt = time.localtime()
df = pd.DataFrame(review_data)
filename = f'./{lt.tm_year}.{lt.tm_mon}.{lt.tm_mday}_{product_name}_ë¦¬ë·°_ì˜¤ëŠ˜ì˜ì§‘.xlsx'
df.to_excel(filename, index=False)
print(f"ğŸ‰ ì´ {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ! â†’ {filename}")
